"""
CLARA Configuration for MVSA-Multiple Dataset

This configuration handles extreme class imbalance (3.2% negative samples)
Achieves 73.51% accuracy on MVSA-Multiple test set.
"""

# Model Architecture
model:
  vision_encoder: "openai/clip-vit-base-patch16"
  text_encoder: "microsoft/deberta-v3-base"
  hidden_dim: 512
  num_classes: 3  # Positive, Neutral, Negative
  
  # LoRA Configuration
  lora_rank: 8
  lora_alpha: 16
  lora_dropout: 0.05
  freeze_encoders: true
  
  # Co-Attention Configuration
  num_attention_heads: 8
  num_attention_layers: 2
  attention_dropout: 0.1
  
  # Classification
  dropout: 0.1

# Training Configuration
training:
  # Optimizer
  optimizer: "adamw"
  learning_rate: 2.0e-5
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # Scheduler
  scheduler: "cosine"
  warmup_ratio: 0.1
  
  # Training Parameters
  batch_size: 32
  num_epochs: 50
  early_stopping_patience: 10
  
  # Loss - IMPORTANT for imbalanced data
  label_smoothing: 0.1
  use_class_weights: true
  
  # Oversampling for negative class (index 2)
  use_oversampling: true
  oversample_factor:
    2: 9.44  # Oversample negative class by 9.44x
  
  # Reproducibility
  seed: 42
  deterministic: true

# Data Configuration
data:
  data_dir: "data/MVSA-Multiple"
  max_text_length: 77
  image_size: 224
  num_workers: 4
  pin_memory: true
  
  # Class distribution
  # Positive: 2,564 (72.1%)
  # Neutral: 879 (24.7%)
  # Negative: 112 (3.2%) <- MINORITY CLASS

# Output Configuration
output:
  output_dir: "outputs/mvsa_multiple"
  save_best_only: true
  save_frequency: 1
  log_frequency: 10

# Evaluation Configuration
evaluation:
  metrics:
    - "accuracy"
    - "f1_weighted"
    - "f1_macro"
    - "precision"
    - "recall"
  
  # Per-class metrics
  class_names:
    - "Positive"
    - "Neutral"
    - "Negative"
  
  # Focus on minority class
  monitor_metric: "f1_macro"  # Better for imbalanced data

# Hardware Configuration
hardware:
  device: "cuda"
  mixed_precision: true
  gradient_accumulation_steps: 1
